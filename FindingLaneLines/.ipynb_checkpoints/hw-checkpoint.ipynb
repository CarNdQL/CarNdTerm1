{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def hsvscale(img):\n",
    "    \"\"\"Applies the HSVscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def hsv_mask(img):\n",
    "    \"\"\"Applies the HSV mask for white & yellow colors\"\"\"\n",
    "    # Define the lower and upper bounds for the white color\n",
    "    white_lwr = np.array([0, 0, 200])\n",
    "    white_upr = np.array([180, 255, 255])\n",
    "    \n",
    "    # Define the lower and upper bounds for the yellow color\n",
    "    yellow_lwr = np.array([20, 100, 100])\n",
    "    yellow_upr = np.array([30, 255, 255])\n",
    "    \n",
    "    # Convert the scale from BGR to HSV\n",
    "    hsv_img = hsvscale(img)\n",
    "    \n",
    "    # Get the white color mask\n",
    "    white_mask = cv2.inRange(hsv_img, white_lwr, white_upr)\n",
    "\n",
    "\n",
    "    # Get the yellow color mask\n",
    "    yellow_mask = cv2.inRange(hsv_img, yellow_lwr, yellow_upr)\n",
    "    \n",
    "    # Combine two masks\n",
    "    mask_combined = white_mask | yellow_mask\n",
    "\n",
    "    # Use bitwise_and to mask the original image\n",
    "    return cv2.bitwise_and(img, img, mask=mask_combined)\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    " \n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "            \n",
    "def draw_lines_ext(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    \"\"\"\n",
    "    This function draws `lines` with `color` and `thickness`.\n",
    "    Lines are devided into two groups, positive & negtive, by their \n",
    "    slope ((y2-y1)/(x2-x1)). Then within each group, average/extrapolate \n",
    "    the line segments to map out the full extent of the lane  \n",
    "    \"\"\"\n",
    "    slopes=[]\n",
    "\n",
    "    #calculate slopes for each line to identify the positive and negative lines\n",
    "    pos_lines = []\n",
    "    neg_lines = []\n",
    "    \n",
    "    #set pos_min_slope/neg_max_slope to remove the near-horizontal lines\n",
    "    pos_min_slope = np.pi*10/180\n",
    "    neg_max_slope = -pos_min_slope\n",
    "    \n",
    "    img_shape = img.shape\n",
    "    min_y=img_shape[0]\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            intercept = y1 - slope * x1\n",
    "            length = math.sqrt((y2 - y1)**2.0 + (x2 - x1)**2.0)\n",
    "            if slope > pos_min_slope:\n",
    "                pos_lines.append((slope, intercept, length))\n",
    "            elif slope < neg_max_slope:\n",
    "                neg_lines.append((slope, intercept, length))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    min_y = np.amin(lines[:,:,[1,3]])\n",
    "        \n",
    "    pos_lines = np.array(pos_lines)\n",
    "    neg_lines = np.array(neg_lines)\n",
    "\n",
    "    #remove outliers\n",
    "    pos_lines = pos_lines[to_keep_index(pos_lines[:, 0])]\n",
    "    neg_lines = neg_lines[to_keep_index(neg_lines[:, 0])]\n",
    "\n",
    "    \n",
    "    # Find the average slope and intercept for each line\n",
    "    # Use line lengths as the weights so that longer segments dominate the averages\n",
    "\n",
    "    pos_lines_slope = np.average(pos_lines[:, 0], weights=pos_lines[:, 2])\n",
    "    pos_lines_intercept = np.average(pos_lines[:, 1], weights=pos_lines[:, 2])\n",
    "\n",
    "    neg_lines_slope = np.average(neg_lines[:, 0], weights=neg_lines[:, 2])\n",
    "    neg_lines_intercept = np.average(neg_lines[:, 1], weights=neg_lines[:, 2])\n",
    "\n",
    "    \n",
    "    pos_y1 = img_shape[0]\n",
    "    pos_x1 = int((pos_y1 - pos_lines_intercept) / pos_lines_slope)\n",
    "\n",
    "    pos_y2 = min_y\n",
    "    pos_x2 = int((pos_y2 - pos_lines_intercept) / pos_lines_slope)\n",
    "\n",
    "    neg_y1 = img_shape[0]\n",
    "    neg_x1 = int((neg_y1 - neg_lines_intercept) / neg_lines_slope)\n",
    "\n",
    "    neg_y2 = min_y\n",
    "    neg_x2 = int((neg_y2 - neg_lines_intercept) / neg_lines_slope)\n",
    "    \n",
    "    cv2.line(img, (pos_x1, pos_y1), (pos_x2, pos_y2), color, thickness)\n",
    "    cv2.line(img, (neg_x1, neg_y1), (neg_x2, neg_y2), color, thickness)\n",
    "    \n",
    "\n",
    "## removing the outliers \n",
    "def to_keep_index(obs, std=1.5):\n",
    "    \"\"\"\n",
    "    Detect the outliers using standard deviation\n",
    "    \"\"\"\n",
    "    return np.array(abs(obs - np.mean(obs)) < std*np.std(obs))\n",
    "    \n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines_ext(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Lane Finding Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "# then save them to the test_images directory.\n",
    "\n",
    "def pipeline(img):\n",
    "\n",
    "    # Apply color selection\n",
    "    hsv_masked_image = hsv_mask(img)\n",
    "\n",
    "    # Convert it into grayscale and display again\n",
    "    gray = grayscale(hsv_masked_image)\n",
    "    \n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray,kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Define a four sided polygon to mask\n",
    "    imshape = img.shape\n",
    "    vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    edges_roi = region_of_interest(edges, vertices)\n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    rho = 2 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 10 #minimum number of pixels making up a line\n",
    "    max_line_gap = 5 \n",
    "    lines = hough_lines(edges_roi, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "\n",
    "    img_output = weighted_img(lines, img)\n",
    "    \n",
    "    return hsv_masked_image, gray, edges_roi, img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Images\n",
    "\n",
    "Test the pipeline on the images in the directory \"test_images\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for img_name in os.listdir(\"test_images/\"):\n",
    "    folder_name = \"test_images\"\n",
    "    path = folder_name + \"/\" + img_name\n",
    "    image = mpimg.imread(path)\n",
    "        \n",
    "    print(img_name.upper())\n",
    "        \n",
    "    hsv_masked_image, gray, edges_roi, image_output = pipeline(image)\n",
    "        \n",
    "    nm, ext = img_name.split(\".\")\n",
    "    \n",
    "    out_file_name = \"test_images_output/\" + nm + \"_hsvMasked.\" + ext\n",
    "    print(out_file_name)\n",
    "    cv2.imwrite(out_file_name, cv2.cvtColor(hsv_masked_image, cv2.COLOR_BGR2RGB ))\n",
    "    plt.imshow(hsv_masked_image)\n",
    "    plt.show()\n",
    "    \n",
    "    out_file_name = \"test_images_output/\" + nm + \"_gray.\" + ext\n",
    "    print(out_file_name)\n",
    "    cv2.imwrite(out_file_name, cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB))\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    out_file_name = \"test_images_output/\" + nm + \"_edge.\" + ext\n",
    "    print(out_file_name)\n",
    "    cv2.imwrite(out_file_name, cv2.cvtColor(edges_roi, cv2.COLOR_GRAY2RGB))\n",
    "    plt.imshow(edges_roi)\n",
    "    plt.show()\n",
    "    \n",
    "    out_file_name = \"test_images_output/\" + nm + \"_out.\" + ext\n",
    "    print(out_file_name)\n",
    "    cv2.imwrite(out_file_name, cv2.cvtColor(image_output, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(image_output)\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Test on Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    try: \n",
    "        hsv_masked_image, gray, edges_roi, image_output = pipeline(image)\n",
    "    except:\n",
    "        image_output = \"error.jpg\"\n",
    "        cv2.imwrite(image_output, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        raise\n",
    "    return image_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try the one with the solid white lane on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "is_video_file = True\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try the one with the solid yellow lane on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Optional Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,5)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
